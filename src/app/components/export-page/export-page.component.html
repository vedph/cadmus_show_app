<div>
  <h1>Data Export</h1>
  <div>
    <div class="banner">
      <img
        class="banner-img"
        srcset="
          ./assets/img/export-1024.jpg 1024w,
          ./assets/img/export-512.jpg   512w
        "
        sizes="(max-width: 600px) 512px, 1024px"
      />
    </div>
  </div>
  <article class="cols">
    <aside class="pquote">
      <blockquote>A Data Hub</blockquote>
    </aside>
    <p>
      As an open and modular content editor, capable of integrating internal and
      external services and linking its data to other resources, Cadmus works as
      a sort of content hub. As such, it is the target of various data import
      procedures, and the source of various data export procedures.
    </p>
    <p>
      Import procedures are more various, and for many of them a sibling
      project, Proteus, can be used to import and remodel data from several
      different sources and digital formats, either standard or even
      proprietary.
    </p>
    <p>
      Export procedures instead rely on the Cadmus content model, and as such
      they can usually be handled in the same way for most cases. An export
      procedure essentially draws data from the Cadmus database, selecting and
      transforming it into some form of output.
    </p>
    <aside class="pquote">
      <blockquote>"Preview" as Export</blockquote>
    </aside>
    <p>
      This also works inside the editor itself, to generate a more
      human-friendly rendition of any data model, a sort of "preview", borrowing
      a term from the old practice of many text editors to generate a print
      preview. Of course, printing or previewing here are out of concern: we are
      just providing a less cluttered and more readable presentation of model
      data. Anyway, in this sense the preview feature itself is just a part of
      the bigger subsystem designed for data export, and is designed to work
      inside the editor, so that operators can better look at the data they
      enter.
    </p>
    <p>
      Thus, in preview, as for any other export procedure, it all starts from
      the Cadmus database, which contains items, with their parts. Some of these
      parts may represent text (with a text part), or layered text (with a text
      part and any number of text layer parts). Many other parts may well
      represent non-textual data (e.g. the codicological description of a
      manuscript).
    </p>
    <p>
      From the perspective of preview, the main types are just two: a
      <em>generic preview</em>, applicable to any part model; and a
      <em>layered text preview</em>, specialized just for text with metadata
      layers.
    </p>
    <aside class="pquote">
      <blockquote>Generic Preview</blockquote>
    </aside>
    <p>
      The generic preview relies on a JSON renderer component, which simply is a
      component which takes JSON (representing any Cadmus data object: part,
      fragment, or item), and renders it into some text-based format, like HTML,
      XML, etc. After its own rendition, a JSON renderer can use any number of
      filters, which further transform its output. Each filter has a specific
      task, often general enough to be reused in other renderers. For instance,
      some prebuilt filters allow you to lookup thesauri (resolving their IDs
      into values), convert Markdown text into HTML or plain text, perform text
      replacements (either based on literals, and on regular expressions), etc.
    </p>
    <p>
      Though you are free to implement your own JSON renderers, most times you
      can just stick to the generic ones, like the XSLT-based renderer. This is
      one of the most customizable renderers, as it chains several
      transformation stages:
    </p>
    <ol>
      <li>
        an optional pipeline of JSON transformations (using the
        <a href="https://jmespath.org/tutorial.html" target="_blank"></a
        >JMESPath query language). This is capable of deeply remodeling the data
        object represented by JSON, by manipulating its own structure.
      </li>
      <li>an implicit and automatic transformation from JSON to XML.</li>
      <li>
        an XSLT-based transformation, which produces the desired output. Cadmus
        models are serialized as JSON; yet, in most cases scholars are much more
        confident with XML and XSLT. So, letting users design their own XSLT
        transformations to get the desired data rendition is a way for combining
        transformation power with ease of use.
      </li>
      <li>
        an optional chain of renderer filters, to further transform the XSLT
        output. For instance, we might want to use a Markdown filter to convert
        Markdown regions into HTML.
      </li>
    </ol>
    <p>
      Given that all these transformations are configurable, and any number of
      modules can be inserted in the pipeline, this renderer alone may be enough
      for a whole project. The only specialization required is usually something
      more complex for layered texts.
    </p>
    <aside class="pquote">
      <blockquote>Layered Text Preview</blockquote>
    </aside>
    <p>
      Layered texts are a complex thing to handle when dealing with
      presentation, right because all the layers stacked on top of the base text
      must be merged down into the flat surface of the text itself. For
      instance, say you have this line of text, where different portions of it
      are annotated at different levels (each represented by a letter):
    </p>
    <table id="sample-text">
      <colgroup>
        <col />
        <col />
        <col />
        <col />
        <col />
        <col />
        <col />
        <col />
        <col />
        <col />
        <col />
        <col />
        <col />
        <col />
        <col />
        <col />
        <col />
        <col />
      </colgroup>
      <tbody>
        <tr>
          <td>q</td>
          <td>u</td>
          <td>e</td>
          <td></td>
          <td>b</td>
          <td>i</td>
          <td>x</td>
          <td>i</td>
          <td>t</td>
          <td></td>
          <td>a</td>
          <td>n</td>
          <td>n</td>
          <td>o</td>
          <td>s</td>
          <td></td>
          <td>X</td>
          <td>X</td>
        </tr>
        <tr>
          <td>.</td>
          <td>.</td>
          <td>O</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
        </tr>
        <tr>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>O</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
        </tr>
        <tr>
          <td>.</td>
          <td>.</td>
          <td>P</td>
          <td>P</td>
          <td>P</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
        </tr>
        <tr>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
          <td>C</td>
          <td>C</td>
          <td>C</td>
          <td>C</td>
          <td>C</td>
          <td>C</td>
          <td>C</td>
          <td>C</td>
          <td>C</td>
          <td>C</td>
          <td>C</td>
          <td>.</td>
          <td>.</td>
          <td>.</td>
        </tr>
      </tbody>
    </table>
    <br />
    <p>
      Here, <code>O</code> represents an orthographic annotation (<em>que</em>
      for <em>quae</em>; <em>bixit</em> for <em>vixit</em>), which happens at
      the maximum level of granularity (the character);
      <code>P</code> represents a paleographic annotation (e.g. a graphical
      connection between <code>E</code> and <code>B</code>); and
      <code>C</code> a generic comment annotation (<em>bixit annos</em> to note
      the usage of accusative rather than the more usual ablative). As you can
      see, each annotation has its own extent: the two orthographic annotations
      rest on single letters (<em>e</em>, <em>b</em>); the paleographic
      annotation links two letters (final <em>e</em> and initial <em>b</em>),
      including the space between them; and the comment annotation spans for a
      couple of words.
    </p>
    <p>
      Most of these spans overlap, but this is not an issue in Cadmus, as each
      rests on its own layer. All what we have is a text part, representing the
      base text, and 3 text layer parts connected to it for orthographic,
      paleographic, and comment annotations. Yet, when we want to present the
      text on a single plane, things get more complicated.
    </p>
    <p>
      To this end, Cadmus provides a special category of export components known
      as text flatteners, whose purpose is right merging all the layers down by
      projecting them on the surface of the base text. This is done by examining
      all the annotations in each layer, and split the text into blocks so that
      each block represents the maximum span of characters linked to exactly the
      same set of annotations, whatever the layer they come from.
    </p>
    <p>
      So, in our case the resulting blocks will produce a text segmentation like
      <code>qu|e| |b|ixit annos| XX</code>, where 6 text blocks are variously
      linked to different layer annotations: for instance, <em>qu</em> is linked
      to none, while the next <em>e</em> is linked to annotations from two
      layers, <code>O</code> and <code>P</code>; and so forth.
    </p>
    <aside class="pquote">
      <blockquote>Flattening Multiple Planes</blockquote>
    </aside>
    <p>
      The following picture shows this remodeling. We start from a
      multidimensional set of annotations, where any number of any type of data
      are distributed on different planes, all linked to a base text. This is
      the Cadmus model, where an item (the box) contains parts (the objects in
      the box). An object is the text itself (the cube with T in the picture);
      other objects represent layers on top of it (the cubes with L). Further,
      the box can eventually contain many other objects which have no direct
      relation with the text (the cube with X). Of course, as Cadmus has an open
      and multilayered architecture, whereas TEI is a giant, yet relatively
      closed standard, often not all these objects might have a corresponding
      set of elements in TEI; and as we have seen, many objects may even be
      non-textual at all. So you typically choose a subset of the objects in the
      box, and eventually a subset of their properties, according to what you
      want to get on the TEI side.
    </p>
    <p>
      When exporting text, we must flatten the selected planes on a single one,
      where all the annotations must be crushed and flattened on a text, modeled
      as a sequence of blocks, as explained above.
    </p>
    <figure>
      <img
        src="./assets/img/text-blocks.png"
        alt="Text blocks"
        style="width: 600px"
      />
      <figcaption>text blocks</figcaption>
    </figure>
    <p>
      So, in the picture each layer is represented by a horizontal band which
      runs parallel to the base text (QVE...XX). In each band there are all the
      annotations (fragments, in Cadmus terms) belonging to that layer. These
      get projected onto the unique surface of the exported text, as shown by
      the red rectangles.
    </p>
    <p>
      The result of these projections is a flattened text, built of blocks; and
      each block is linked to any number of annotations, each in its own layer.
    </p>
    <p>
      With this model in place, we can easily present the text with as a list of
      rows, each including a sequence of such blocks. Wherever we have a linked
      block, a different color is used according to the layer. When the user
      clicks on any linked block, he gets the rendition of the corresponding
      annotation, which just uses the generic preview mechanism illustrated
      above.
    </p>
    <p>
      Additionally, with the same model, we can serialize it into a standard
      format like TEI with stand-off annotation. This is as easy as writing all
      the blocks to a TEI text file, wrapping them in a neutral element like
      <code>seg</code>, which gets a unique ID assigned. Then, we will have
      another TEI file, one for each layer, having all the annotations from its
      layer rendered in some TEI inside a <code>standOff</code> element. The
      elements in the standoff section will be linked to the <code>seg</code>
      elements in the text file via the segment's ID.
    </p>
    <p>
      This also has an advantage over a traditional stand-off TEI: there, we
      typically start by systematically splitting the text at a predefined level
      of granularity, e.g. a "word". So, we will wrap every single word of the
      text in <code>seg</code>, even though these elements will never be the
      target of an annotation, because we can't know in advance whether this
      will be required or not. This can be quickly result in an extremely
      redundant and confusing text. Also, we are bound to the pre-selected level
      of granularity, which in our sample is the "word"; should we ever want to
      annotate something at a lower level (e.g. a syllable or even a single
      character), this won't be possible, unless we manually edit the prepared
      text. This can easily become a nightmare, both in terms of creation and
      maintenance.
    </p>
    <p>
      In Cadmus instead, TEI is just an automatic rendition of a more structured
      and open set of data; so, when we decide which layers we want to export,
      we already know in advance exactly which portions of it will require to be
      wrapped in a <code>seg</code> element, whatever their extension, from a
      single character to many words. This is right what provides us this text
      blocks model, produced by text flatteners. The same model serves both the
      logic of interactive presentation in a UI and export processes towards
      third party standards. We thus get a more readable and more compact
      standoff TEI, which can be totally rebuilt whenever we want to add new
      layers, or just synchronize the output with our edits.
    </p>
  </article>
</div>
